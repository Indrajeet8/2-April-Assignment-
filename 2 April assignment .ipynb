{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5450575f-65a8-4877-8b57-a72d3815630e",
   "metadata": {},
   "source": [
    "## Logistic Regression-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6dd339-15f3-4fb6-ab1c-094026d89ccf",
   "metadata": {},
   "source": [
    "Assignment Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1d5a41-2968-45be-bd7c-e3117c9ab0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is the purpose of grid search cv in machine learning, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb95927-9fdc-464e-8817-822ab0c7e151",
   "metadata": {},
   "source": [
    "What is GridSearchCV used for? GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid. It's essentially a cross-validation technique. The model as well as the parameters must be entered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee40a41-6d3f-4b9d-858d-a7c83775c842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f01d24-a638-463c-8d14-5f99f3460884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose one over the other?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7a88f-ef07-4889-befb-01d7b2e7c9a6",
   "metadata": {},
   "source": [
    "The only difference between both the approaches is in grid search we define the combinations and do training of the model whereas in RandomizedSearchCV the model selects the combinations randomly. Both are very effective ways of tuning the parameters that increase the model generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ec7a1-6650-4244-ba3b-9562588cd6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49b4d01-213e-41a1-8bee-b5b5062b4468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is data leakage, and why is it a problem in machine learning? Provide an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b36029-07d5-418c-b8af-c62c2030caea",
   "metadata": {},
   "source": [
    "Data leakage (or leakage) happens when your training data contains information about the target, but similar data will not be available when the model is used for prediction. This leads to high performance on the training set (and possibly even the validation data), but the model will perform poorly in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250cb20d-eb35-4754-a933-3527e0af48be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3a0d44-cba1-4249-87a4-258e01692af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. How can you prevent data leakage when building a machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569afd3-ec3d-452b-9f87-62b07bd1bc34",
   "metadata": {},
   "source": [
    "Data leakage is a serious issue in machine learning, as it can lead to models that perform poorly on new data. There are a number of steps that can be taken to prevent data leakage, including:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77601188-f44c-4143-97c3-8534c3347173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d627d1-b3ef-4f11-9c41-37584ad13f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64012b-1297-4f93-82ed-3f39b2d51f61",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that allows you to visualize the performance of a classification model. You can also use the information in it to calculate measures that can help you determine the usefulness of the model. Rows represent predicted classifications, while columns represent the true classes from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028efd9-0a26-4714-8465-d153e4037264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d92c9690-735c-48fc-97ff-43e571b6dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Explain the difference between precision and recall in the context of a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d77bc-6450-4ffd-949d-d1c6ecb38eed",
   "metadata": {},
   "source": [
    "The precision is the proportion of relevant results in the list of all returned search results. The recall is the ratio of the relevant results returned by the search engine to the total number of the relevant results that could have been returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cfc6d2-4037-40c2-bc9c-e7c595f7635d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff5c608-db22-44bc-92cd-1316faa95780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bdb142-f31e-457b-a15c-9a0f8c00dd20",
   "metadata": {},
   "source": [
    "The confusion matrix shows the number of correct predictions: true positives (TP) and true negatives (TN). It also shows the model errors: false positives (FP) are “false alarms,” and false negatives (FN) are missed cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a06f9-14ba-4829-b70e-5e67343f75de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ce90eb-be9a-4b84-8958-cc352c0c2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. What are some common metrics that can be derived from a confusion matrix, and how are they calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a4e1d-542c-4e49-8d05-11514efb1348",
   "metadata": {},
   "source": [
    "Confusion matrices can be used to calculate performance metrics for classification models. Of the many performance metrics used, the most common are accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07806212-68a9-4821-864d-10bc42d838ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f2fb5a-1c17-4cd3-b434-1f1388ccbcd4",
   "metadata": {},
   "source": [
    "Here are some of the most common performance measures you can use from the confusion matrix. Accuracy: It gives you the overall accuracy of the model, meaning the fraction of the total samples that were correctly classified by the classifier. To calculate accuracy, use the following formula: (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6538f5-28df-42bc-917f-a0b66e38daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
